@article{Blalock2020,
archivePrefix = {arXiv},
arxivId = {2003.03033},
author = {Blalock, Davis and Ortiz, Jose Javier Gonzalez and Frankle, Jonathan and Guttag, John},
eprint = {2003.03033},
file = {:home/abanoub_g/gits/NetZIP/papers/WHAT IS THE STATE OF NEURAL NETWORK PRUNING.pdf:pdf},
title = {{What is the State of Neural Network Pruning?}},
url = {http://arxiv.org/abs/2003.03033},
year = {2020}
}

@article{Babaeizadeh2016,
archivePrefix = {arXiv},
arxivId = {1611.06211},
author = {Babaeizadeh, Mohammad and Smaragdis, Paris and Campbell, Roy H.},
eprint = {1611.06211},
file = {:home/abanoub_g/gits/NetZIP/papers/NoiseOut\: A Simple Way to Prune Neural Networks.pdf:pdf},
number = {Nips},
title = {{NoiseOut: A Simple Way to Prune Neural Networks}},
url = {http://arxiv.org/abs/1611.06211},
year = {2016}
}

@article{Zhou2019a,
archivePrefix = {arXiv},
arxivId = {1905.01067},
author = {Zhou, Hattie and Lan, Janice and Liu, Rosanne and Yosinski, Jason},
eprint = {1905.01067},
file = {:home/abanoub_g/gits/NetZIP/papers/Deconstructing Lottery Tickets.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {NeurIPS},
title = {{Deconstructing lottery tickets: Zeros, signs, and the supermask}},
volume = {32},
year = {2019}
}

@article{Gholami2022,
archivePrefix = {arXiv},
arxivId = {2103.13630},
author = {Gholami, Amir and Kim, Sehoon and Dong, Zhen and Yao, Zhewei and Mahoney, Michael W. and Keutzer, Kurt},
doi = {10.1201/9781003162810-13},
eprint = {2103.13630},
file = {:home/abanoub_g/gits/NetZIP/papers/A Survey of Quantization Methods for Efficient.pdf:pdf},
journal = {Low-Power Computer Vision},
pages = {291--326},
title = {{A Survey of Quantization Methods for Efficient Neural Network Inference}},
year = {2022}
}

@article{Liang2021,
archivePrefix = {arXiv},
arxivId = {2101.09671},
author = {Liang, Tailin and Glossner, John and Wang, Lei and Shi, Shaobo and Zhang, Xiaotong},
doi = {10.1016/j.neucom.2021.07.045},
eprint = {2101.09671},
file = {:home/abanoub_g/gits/NetZIP/papers/Pruning and quantization for deep neural network acceleration\: A survey.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Convolutional neural network,Low-bit mathematics,Neural network acceleration,Neural network pruning,Neural network quantization},
pages = {370--403},
publisher = {Elsevier B.V.},
title = {{Pruning and quantization for deep neural network acceleration: A survey}},
url = {https://doi.org/10.1016/j.neucom.2021.07.045},
volume = {461},
year = {2021}
}

@article{Neill2020,
archivePrefix = {arXiv},
arxivId = {2006.03669},
author = {Neill, James O'},
eprint = {2006.03669},
file = {:home/abanoub_g/gits/NetZIP/papers/A Survey of Neural Network Compression.pdf:pdf},
pages = {1--73},
title = {{An Overview of Neural Network Compression}},
url = {http://arxiv.org/abs/2006.03669},
year = {2020}
}

@article{Yang2019,
archivePrefix = {arXiv},
arxivId = {1911.09464},
author = {Yang, Jiwei and Shen, Xu and Xing, Jun and Tian, Xinmei and Li, Houqiang and Deng, Bing and Huang, Jianqiang and Hua, Xian Sheng},
doi = {10.1109/CVPR.2019.00748},
eprint = {1911.09464},
file = {:home/abanoub_g/gits/NetZIP/papers/Quantization Networks.pdf:pdf},
isbn = {9781728132938},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
keywords = {Categorization,Deep Learning,Recognition: Detection,Retrieval},
pages = {7300--7308},
title = {{Quantization networks}},
volume = {2019-June},
year = {2019}
}

@article{Marino2023,
author = {Marin{\'{o}}, Giosu{\'{e}} Cataldo and Petrini, Alessandro and Malchiodi, Dario and Frasca, Marco},
doi = {10.1016/j.neucom.2022.11.072},
file = {:home/abanoub_g/gits/AG_PhD_iCASE/LiteratureReview1_ML_Testing/Papers/DeepNeuralNetworksCompressionAComparativeSurveyAndChoiceRecommendations.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {CNN compression,Connection pruning,Huffman coding,Succinct Deep Neural Networks,Weight quantization,Weight sharing},
pages = {152--170},
title = {{Deep neural networks compression: A comparative survey and choice recommendations}},
volume = {520},
year = {2023}
}

@software{nni2021,
   author = {{Microsoft}},
   month = {1},
   title = {{Neural Network Intelligence}},
   url = {https://github.com/microsoft/nni},
   version = {2.0},
   year = {2021}
}

@article{Ghobrial2022,
archivePrefix = {arXiv},
arxivId = {2205.00147},
author = {Ghobrial, Abanoub and Zheng, Xuan and Hond, Darryl and Asgari, Hamid and Eder, Kerstin},
eprint = {2205.00147},
file = {:home/abanoub_g/Downloads/OperationalAdaptationOfDNNClassifiersUsingElasticWeight.pdf:pdf},
pages = {1--13},
title = {{Operational Adaptation of DNN Classifiers using Elastic Weight Consolidation}},
url = {http://arxiv.org/abs/2205.00147},
year = {2022}
}

@article{determinisim,
  author    = {Greg Chance and
               Abanoub Ghobrial and
               Kevin McAreavey and
               S{\'{e}}verin Lemaignan and
               Tony Pipe and
               Kerstin Eder},
  title     = {On Determinism of Game Engines used for Simulation-based Autonomous
               Vehicle Verification},
  year      = {2021},
  url       = {https://arxiv.org/abs/2104.06262},
  eprinttype = {arXiv},
  eprint    = {2104.06262}
}

@software{Jocher_YOLOv5_by_Ultralytics_2020,
author = {Jocher, Glenn},
doi = {10.5281/zenodo.3908559},
license = {GPL-3.0},
month = {5},
title = {{YOLOv5 by Ultralytics}},
url = {https://github.com/ultralytics/yolov5},
version = {7.0},
year = {2020}
}

@software{pyRAPL_repo,
author = {PowerAPI},
title = {{pyRAPL}},
url = {https://github.com/powerapi-ng/pyRAPL},
year = {2019}
}

@inproceedings{Field2014,
author = {Field, Hayden and Anderson, Glen and Eder, Kerstin},
title = {EACOF: A Framework for Providing Energy Transparency to Enable Energy-Aware Software Development},
year = {2014},
isbn = {9781450324694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2554850.2554920},
doi = {10.1145/2554850.2554920},
booktitle = {Proceedings of the 29th Annual ACM Symposium on Applied Computing},
pages = {1194â€“1199},
numpages = {6},
keywords = {abstraction, energy profiling, energy transparency, energy-aware computing, eacof},
location = {Gyeongju, Republic of Korea},
series = {SAC '14}
}

@misc{fang2023depgraph,
      title={DepGraph: Towards Any Structural Pruning}, 
      author={Gongfan Fang and Xinyin Ma and Mingli Song and Michael Bi Mi and Xinchao Wang},
      year={2023},
      eprint={2301.12900},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{fan2020pyslowfast,
  author =       {Haoqi Fan and Yanghao Li and Bo Xiong and Wan-Yen Lo and Christoph Feichtenhofer},
  title =        {PySlowFast},
  howpublished = {\url{https://github.com/facebookresearch/slowfast}},
  year =         {2020}
}

@article{paszke2017automatic,
  title={Automatic differentiation in PyTorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  year={2017}
}


@article{Menghani2023,
archivePrefix = {arXiv},
arxivId = {2106.08962},
author = {Menghani, Gaurav},
doi = {10.1145/3578938},
eprint = {2106.08962},
file = {:home/abanoub_g/gits/NetZIP/paper/Literature_papers/Efficient Deep Learning\: A Survey on Making Deep Learning Models Smaller, Faster, and Better.pdf:pdf},
issn = {0360-0300},
journal = {ACM Computing Surveys},
number = {12},
pages = {1--37},
title = {{Efficient Deep Learning: A Survey on Making Deep Learning Models Smaller, Faster, and Better}},
volume = {55},
year = {2023}
}

@article{Blalock2018,
archivePrefix = {arXiv},
arxivId = {1808.02515},
author = {Blalock, Davis and Madden, Samuel and Guttag, John},
doi = {10.1145/3264903},
eprint = {1808.02515},
file = {:home/abanoub_g/gits/NetZIP/paper/Literature_papers/Sprintz\: Time Series Compression for the Internet of Things.pdf:pdf},
number = {3},
title = {{Sprintz: Time Series Compression for the Internet of Things}},
url = {http://arxiv.org/abs/1808.02515%0Ahttp://dx.doi.org/10.1145/3264903},
volume = {2},
year = {2018}
}

@article{He2018,
archivePrefix = {arXiv},
arxivId = {1802.03494},
author = {He, Yihui and Lin, Ji and Liu, Zhijian and Wang, Hanrui and Li, Li Jia and Han, Song},
doi = {10.1007/978-3-030-01234-2_48},
eprint = {1802.03494},
file = {:home/abanoub_g/gits/NetZIP/paper/Literature_papers/Automl for model compression and accelera- tion on mobile devices..pdf:pdf},
isbn = {9783030012335},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {AutoML,CNN acceleration,Mobile vision,Model compression,Reinforcement learning},
pages = {815--832},
title = {{AMC: AutoML for model compression and acceleration on mobile devices}},
volume = {11211 LNCS},
year = {2018}
}

@inproceedings{Chance_2020,
      doi = {10.1109/aitest49225.2020.00012},
  
      url = {https://doi.org/10.1109%2Faitest49225.2020.00012},
  
      year = 2020,
      month = {aug},
  
      publisher = {{IEEE}
},
  
      author = {Greg Chance and Abanoub Ghobrial and Severin Lemaignan and Tony Pipe and Kerstin Eder},
  
      title = {An Agency-Directed Approach to Test Generation for Simulation-based Autonomous Vehicle Verification},
  
      booktitle = {2020 {IEEE} International Conference On Artificial Intelligence Testing ({AITest})}
}

@misc{mirza2022norm,
      title={The Norm Must Go On: Dynamic Unsupervised Domain Adaptation by Normalization}, 
      author={M. Jehanzeb Mirza and Jakub Micorek and Horst Possegger and Horst Bischof},
      year={2022},
      eprint={2112.00463},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@misc{courbariaux2016binarized,
      title={Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1}, 
      author={Matthieu Courbariaux and Itay Hubara and Daniel Soudry and Ran El-Yaniv and Yoshua Bengio},
      year={2016},
      eprint={1602.02830},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{esser2020learned,
      title={Learned Step Size Quantization}, 
      author={Steven K. Esser and Jeffrey L. McKinstry and Deepika Bablani and Rathinakumar Appuswamy and Dharmendra S. Modha},
      year={2020},
      eprint={1902.08153},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{yang2022oneshot,
      title={One-shot Network Pruning at Initialization with Discriminative Image Patches}, 
      author={Yinan Yang and Yu Wang and Ying Ji and Heng Qi and Jien Kato},
      year={2022},
      eprint={2209.05683},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{frankle2019lottery,
      title={The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks}, 
      author={Jonathan Frankle and Michael Carbin},
      year={2019},
      eprint={1803.03635},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{feichtenhofer2019slowfast,
      title={SlowFast Networks for Video Recognition}, 
      author={Christoph Feichtenhofer and Haoqi Fan and Jitendra Malik and Kaiming He},
      year={2019},
      eprint={1812.03982},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{Brown2020,
  author       = {Tom B. Brown and
                  Benjamin Mann and
                  Nick Ryder and
                  Melanie Subbiah and
                  Jared Kaplan and
                  Prafulla Dhariwal and
                  Arvind Neelakantan and
                  Pranav Shyam and
                  Girish Sastry and
                  Amanda Askell and
                  Sandhini Agarwal and
                  Ariel Herbert{-}Voss and
                  Gretchen Krueger and
                  Tom Henighan and
                  Rewon Child and
                  Aditya Ramesh and
                  Daniel M. Ziegler and
                  Jeffrey Wu and
                  Clemens Winter and
                  Christopher Hesse and
                  Mark Chen and
                  Eric Sigler and
                  Mateusz Litwin and
                  Scott Gray and
                  Benjamin Chess and
                  Jack Clark and
                  Christopher Berner and
                  Sam McCandlish and
                  Alec Radford and
                  Ilya Sutskever and
                  Dario Amodei},
  title        = {Language Models are Few-Shot Learners},
  journal      = {CoRR},
  volume       = {abs/2005.14165},
  year         = {2020},
  url          = {https://arxiv.org/abs/2005.14165},
  eprinttype    = {arXiv},
  eprint       = {2005.14165},
  timestamp    = {Wed, 03 Jun 2020 11:36:54 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2005-14165.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{he2015deep,
      title={Deep Residual Learning for Image Recognition}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Toronto, ON, Canada}
}

@inproceedings{imagenet_cvpr09,
        AUTHOR = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
        TITLE = {{ImageNet: A Large-Scale Hierarchical Image Database}},
        BOOKTITLE = {CVPR09},
        YEAR = {2009},
        BIBSOURCE = "http://www.image-net.org/papers/imagenet_cvpr09.bib"}


@misc{lin2015microsoft,
      title={Microsoft COCO: Common Objects in Context}, 
      author={Tsung-Yi Lin and Michael Maire and Serge Belongie and Lubomir Bourdev and Ross Girshick and James Hays and Pietro Perona and Deva Ramanan and C. Lawrence Zitnick and Piotr DollÃ¡r},
      year={2015},
      eprint={1405.0312},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{BNNs,
  author       = {Matthieu Courbariaux and
                  Yoshua Bengio},
  title        = {BinaryNet: Training Deep Neural Networks with Weights and Activations
                  Constrained to +1 or -1},
  journal      = {CoRR},
  volume       = {abs/1602.02830},
  year         = {2016},
  url          = {http://arxiv.org/abs/1602.02830},
  eprinttype    = {arXiv},
  eprint       = {1602.02830},
  timestamp    = {Mon, 13 Aug 2018 16:46:57 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/CourbariauxB16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{TNNs,
  author={Liu, Bin and Li, Fengfu and Wang, Xiaoxing and Zhang, Bo and Yan, Junchi},
  booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Ternary Weight Networks}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  doi={10.1109/ICASSP49357.2023.10094626}}

@inproceedings{petersen2022differentiable,
  title={Differentiable top-k classification learning},
  author={Petersen, Felix and Kuehne, Hilde and Borgelt, Christian and Deussen, Oliver},
  booktitle={International Conference on Machine Learning},
  pages={17656--17668},
  year={2022},
  organization={PMLR}
}

@inproceedings{Budgett2022,
author = {S. Budgett and P. de Waard},
title = {{Quantized neural networks for modulation recognition}},
volume = {12113},
booktitle = {Artificial Intelligence and Machine Learning for Multi-Domain Operations Applications IV},
editor = {Tien Pham and Latasha Solomon},
organization = {International Society for Optics and Photonics},
publisher = {SPIE},
pages = {1211317},
keywords = {Resource-constrained AI processing, AI Architectures, Edge Computing, Signal Processing, Embedded Systems, Machine Learning, Modulation Recognition, Electromagnetic Spectrum},
year = {2022},
doi = {10.1117/12.2617678},
URL = {https://doi.org/10.1117/12.2617678}
}

@techreport{NVIDIA_TURING_GPU_ARCHITECTURE_2018,
  author = {{NVIDIA}},
  publisher = {{NVIDIA}},
  title = {NVIDIA TURING GPU ARCHITECTURE},
  year = 2018
}


@software{psutil2019,
author = {Rodola, Giampaolo and Loden, Jay and Daeschler, Dave},
license = BSD,
month = {5},
title = {{psutil}},
url = {https://github.com/giampaolo/psutil},
year = {2009}
}

@techreport{NVIDIA_SMI,
  author = {{NVIDIA}},
  publisher = {{NVIDIA}},
  title = {nvidia-smi - NVIDIA System Management Interface program},
  year = 2016
}